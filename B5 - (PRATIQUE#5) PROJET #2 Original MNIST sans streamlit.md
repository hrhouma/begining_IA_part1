# (PRATIQUE#5) PROJET #2 Original MNIST

G√©n√©r√© automatiquement par Colab.

Le fichier original se trouve √† l'adresse suivante :
[Colab](https://colab.research.google.com/drive/13B7oPTQ5OEOeLiFdA_nA_UVMU2p7t6zd)


# T√¢che 1 : Introduction

Bienvenue dans la classification d'images basiques avec TensorFlow.

Ce graphique d√©crit visuellement le probl√®me que nous tentons de r√©soudre. Nous voulons cr√©er et entra√Æner un mod√®le qui prend une image de chiffre √©crit √† la main comme entr√©e et pr√©dit la classe de ce chiffre.

![Classification de chiffres √©crits √† la main](https://drive.google.com/uc?export=view&id=1OZMTtcN1l-xVu8YXtU9qAUUHBs6ZmYzt)

# 1 - Importation de TensorFlow

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.callbacks import TensorBoard
import os
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
```

- Voici une description d√©taill√©e de chaque librairie import√©e :

1. **tensorflow** : TensorFlow est une biblioth√®que open-source d√©velopp√©e par Google pour le machine learning et le deep learning. Elle fournit des outils pour la cr√©ation et l'entra√Ænement de r√©seaux de neurones, ainsi que des primitives pour l'optimisation et le calcul sur des tenseurs.

2. **keras** : Keras est une API haut niveau pour la construction de r√©seaux de neurones. Elle permet de cr√©er, entra√Æner et d√©ployer des mod√®les de mani√®re rapide et intuitive. Depuis TensorFlow 2.0, Keras est int√©gr√© nativement √† TensorFlow, ce qui permet d'utiliser les fonctionnalit√©s de TensorFlow tout en b√©n√©ficiant de la simplicit√© de l'API Keras.

3. **TensorBoard** : TensorBoard est un outil de visualisation fourni par TensorFlow. Il permet de visualiser les graphes computationnels, de suivre la progression de l'entra√Ænement des mod√®les, d'analyser les performances, etc. L'import de `TensorBoard` ici indique probablement l'intention d'utiliser TensorBoard pour le suivi de la formation des mod√®les.

4. **os** : Le module `os` fournit des fonctionnalit√©s li√©es au syst√®me d'exploitation. Il est utilis√© ici pour interagir avec le syst√®me de fichiers, comme la cr√©ation de r√©pertoires ou la manipulation de chemins de fichiers.

5. **numpy** : NumPy est une biblioth√®que tr√®s populaire pour le calcul num√©rique en Python. Elle fournit des structures de donn√©es telles que les tableaux multidimensionnels (ndarray), ainsi que des fonctions pour effectuer des op√©rations math√©matiques sur ces tableaux.

6. **matplotlib.pyplot** : Matplotlib est une biblioth√®que de visualisation en Python. Le sous-module `pyplot` fournit une interface similaire √† celle de MATLAB pour la cr√©ation de graphiques. Il est couramment utilis√© pour tracer des courbes, des histogrammes, des diagrammes en barres, etc.

7. **datetime** : Le module `datetime` fournit des classes et des fonctions pour manipuler des dates et des heures en Python. Il est utilis√© ici probablement pour travailler avec des objets de date et d'heure, peut-√™tre pour enregistrer des horodatages ou pour g√©n√©rer des noms de fichiers uniques.

# R√©sum√©: 
- ce code importe diff√©rentes biblioth√®ques n√©cessaires pour le d√©veloppement et l'entra√Ænement de mod√®les de machine learning avec TensorFlow, ainsi que pour la manipulation de donn√©es, la visualisation et la gestion du syst√®me de fichiers.

# T√¢che 2 : Le Dataset

# 2 - Importation de MNIST

```python
# Chargement des donn√©es MNIST
fashion_mnist_data = keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = fashion_mnist_data.load_data()
```


# T√¢che 3 : Encodage One Hot

Apr√®s cet encodage, chaque √©tiquette sera convertie en une liste de 10 √©l√©ments o√π l'√©l√©ment √† l'indice correspondant √† la classe sera mis √† 1, le reste √† 0.

# 3 -  Encodage des √©tiquettes

```python
from tensorflow.keras.utils import to_categorical

y_train_encoded = to_categorical(y_train)
y_test_encoded = to_categorical(y_test)
```

# T√¢che 4 : R√©seaux Neuronaux

# 4 - √âquations Lin√©aires

![Neurone simple](https://drive.google.com/uc?export=view&id=1X53G3QBhSBZsCHchyvgOsRrczmh0IoXY)

Le graphique ci-dessus repr√©sente simplement l'√©quation :

$$
y = w1 * x1 + w2 * x2 + w3 * x3 + b
$$

o√π `w1, w2, w3` sont appel√©s les poids et `b` est un terme d'interception appel√© biais. L'√©quation peut √©galement √™tre *vectoris√©e* comme ceci :

$$
y = W . X + b
$$

o√π `X = [x1, x2, x3]` et `W = [w1, w2, w3].T`. .T signifie *transpos√©*. Ceci est n√©cessaire car nous voulons que le produit scalaire nous donne le r√©sultat souhait√©, c'est-√†-dire `w1 * x1 + w2 * x2 + w3 * x3`. Cela nous donne la version vectoris√©e de notre √©quation lin√©aire.

Un approche simple et lin√©aire pour r√©soudre le probl√®me de classification d'images de chiffres √©crits √† la main - pourrait-elle fonctionner ?

![Neurone simple avec 784 caract√©ristiques](https://drive.google.com/uc?export=view&id=1usn-vb6FOIOkDuKOimQuFDgGwVSckG5W)



### R√©seaux Neuronaux

![R√©seau neuronal avec 2 couches cach√©es](https://drive.google.com/uc?export=view&id=1-P9jSpGodu2fl-cvEXun3_zQytJDH5Yn)

Ce mod√®le est bien plus susceptible de r√©soudre le probl√®me car il peut apprendre des mappings de fonctions plus complexes pour les entr√©es et les sorties de notre ensemble de donn√©es.

## T√¢che 5 : Pr√©traitement des Exemples

# 5 - Transformation des tableaux N-dimensionnels en Vecteurs

```python
import numpy as np

x_train_reshaped = np.reshape(x_train, (60000, 784))
x_test_reshaped = np.reshape(x_test, (10000, 784))
print('Forme de x_train_reshaped', x_train_reshaped.shape)
print('Forme de x_test_reshaped', x_test_reshaped.shape)
```



# 5.1 - Affichage des valeurs des pixels

```python
print(set(x_train_reshaped[0]))
```

# 5.2 -  Normalisation des donn√©es

```python
x_mean = np.mean(x_train_reshaped)
x_std = np.std(x_train_reshaped)

epsilon = 1e-10

x_train_norm = (x_train_reshaped - x_mean) / (x_std + epsilon)
x_test_norm = (x_test_reshaped - x_mean) / (x_std + epsilon)
```



# 5.3 - Affichage des valeurs des pixels normalis√©s

```python
print(set(x_train_norm[0]))
```

## T√¢che 6 : Cr√©ation d'un Mod√®le

# 6.1 - Cr√©ation du Mod√®le

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(128, activation='relu', input_shape=(784,)),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])
model.summary()
```

# 6.2 -Fonctions d'Activation

La premi√®re √©tape dans le noeud est la somme lin√©aire des entr√©es :

$$
Z = W . X + b
$$

La deuxi√®me √©tape dans le noeud est la sortie de la fonction d'activation :

$$
A = f(Z)
$$

### Repr√©sentation graphique d'un noeud o√π les deux op√©rations sont

![ReLU](https://drive.google.com/uc?export=view&id=1QYbrKPd5_4Lz89q3faOn0ZE-JPbAljV4)

# 6.3 - Compilation du Mod√®le

```python
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

## T√¢che 7 : Entra√Ænement du Mod√®le

# 7.1 - Entra√Ænement du Mod√®le

```python
model.fit(x_train_norm, y_train_encoded, epochs=3)
```

# 7.2 - √âvaluation du Mod√®le

```python
loss, accuracy = model.evaluate(x_test_norm, y_test_encoded)
print('Pr√©cision sur le jeu de test :', accuracy * 100)
```



## T√¢che 8 : Pr√©dictions

# 8.1 - Pr√©dictions sur le jeu de test

```python
preds = model.predict(x_test_norm)
print('Forme des pr√©dictions :', preds.shape)
```

# 8.2 - Affichage des R√©sultats

```python
import matplotlib.pyplot as plt
import numpy as np

plt.figure(figsize=(12, 12))
start_index = 0

for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])

    pred = np.argmax(preds[start_index+i])
    gt = y_test[start_index+i]
    col = 'g' if pred == gt else 'r'

    plt.xlabel('i={}, pr√©d={}, vr={}'.format(start_index+i, pred, gt), color=col)
    plt.imshow(x_test[start_index+i], cmap='binary')

plt.show()
```

# 8.3 - Affichage d'un Graphique de Pr√©dictions

```python
plt.plot(preds[8])
plt.show()
```

- Ce README d√©crit de mani√®re d√©taill√©e chaque √©tape, depuis l'importation des donn√©es jusqu'√† la pr√©diction, en passant par la cr√©ation et l'entra√Ænement du mod√®le. Cela aide √† comprendre comment construire, entra√Æner et √©valuer un mod√®le de classification d'images avec TensorFlow, en utilisant le dataset MNIST.




# (IMPORTANT) - ANNEXES et Points de discussion

## 1. Description des librairies üìö
- Dans ce projet, nous utilisons plusieurs librairies pour le d√©veloppement et l'entra√Ænement de mod√®les de machine learning avec TensorFlow.
- Voici une br√®ve description de chacune d'entre elles :
  
```python
import tensorflow as tf               # TensorFlow, une biblioth√®que de machine learning et de deep learning.
from tensorflow import keras          # Keras, une API haut niveau pour la cr√©ation de r√©seaux de neurones.
from tensorflow.keras.callbacks import TensorBoard  # TensorBoard, un outil de visualisation pour suivre l'entra√Ænement des mod√®les.
import os                             # Le module os, pour interagir avec le syst√®me de fichiers.
import numpy as np                    # NumPy, une biblioth√®que pour le calcul num√©rique.
import matplotlib.pyplot as plt       # Matplotlib, une biblioth√®que de visualisation.
from datetime import datetime         # Le module datetime, pour manipuler des dates et des heures.
```

## 2. Donn√©es d'entra√Ænement et de test üìä
- Il est essentiel de comprendre la taille et les types de donn√©es d'entra√Ænement et de test pour un bon pr√©traitement des donn√©es.

## 3. Encodage One Hot vs alternative Categorical üé®
- L'encodage One Hot est souvent utilis√© pour repr√©senter des cat√©gories dans les donn√©es.
- Alternativement, l'encodage cat√©gorique peut √™tre utilis√©.

## 4. √âquation lin√©aire et biais üìà
- Une explication de l'√©quation lin√©aire et du r√¥le des biais dans les mod√®les lin√©aires.

## 5. Transformation des tableaux N-dimensionnels en vecteurs üîÑ
- Utilisation des fonctions `reshape` ou la couche d'entr√©e `Flatten` pour transformer des tableaux N-dimensionnels en vecteurs.

## 6. Bonnes pratiques üåü
- Affichage des images, types de donn√©es, et v√©rification continue du d√©veloppement.

## 7. Normalisation vs Standardisation des donn√©es üìä
- Comparaison de la normalisation et de la standardisation des donn√©es, avec des exemples dans deux projets diff√©rents.

## 8. Construction du mod√®le üèóÔ∏è
- Comparaison entre deux approches de construction de mod√®les dans deux projets distincts.
- Comparaison entre les deux approches dans le projet 1 et projet 2.

## 9. Fonctions d'activation ‚ö°
Exploration des diff√©rentes fonctions d'activation utilis√©es dans les couches des r√©seaux neuronaux.

## 10. Param√®tre batch_size et concept des hyperparam√®tres üöÄ
- Utilisation du param√®tre `batch_size` dans la compilation et l'entra√Ænement des mod√®les, avec une explication du concept des hyperparam√®tres.

## 11. Accuracy sur les donn√©es de Test ‚úÖ
Explication du concept d'accuracy sur les donn√©es de test, avec du code illustratif.


# (IMPORTANT) Points de discussion


1 - description des librairies  

2 - Donn√©es d'entrainement et de test, importance de voir la taille de vos donn√©es, ainsi que les types de vos donn√©es (pr√©traitement) 

3 - Encodage One Hot sinon alternative Categorical 

4 - C'est quoi √©qualition lin√©aire et les biais (udem exemple) 

5 - N√©cesssit√© de transformer des tableaux N-dimensionnels en Vecteurs soir en utilisant la fonction reshape ou Flatten dans l'autre code 

6 - Bonne pratiques : affichage des images , des types de donn√©es , v√©rification √† fur et √† mesure du d√©veloppement.  

7 - Normalisation vs Standardisation des donn√©es (N√©cessit√© pour un algorithme IA + Les exemples dans les 2 projets projet1 normalisation avec un code simple et projet2 standadisation bas niveau  avec un code plus compliqu√© - comparaison des codes) 

8 - Construction du mod√®le (comparaison entre les deux approches dans le projet 1 et projet 2) 

9  -Fonctions d'activations  

10 - Pour la compilation et le fonction fit, on peut ajouter le param√®tre batch_size 32, 64 , (ce qui explique le 1875 affich√© alors que nous avons 60.0000 images ==> Concept des hyperparam√®tres) 

11 - Concepts d'accuracy sur les donn√©es de Test + code


# Annexe 1  (bias) : Comprendre le Biais dans les R√©seaux Neuronaux

Expliquons le concept de biais (bias) dans les r√©seaux neuronaux:


## Introduction

Lorsqu'on parle de r√©seaux neuronaux, il est courant d'entendre parler de poids (weights) et de biais (bias). Si vous √™tes familier avec les pixels d'une image comme entr√©es d'un mod√®le, et les poids comme coefficients qui ajustent l'importance de ces entr√©es, le concept de biais peut sembler un peu moins intuitif. Dans ce document, nous allons explorer ce qu'est le biais, pourquoi il est crucial dans les mod√®les d'apprentissage automatique, et comment il fonctionne avec des analogies simples et des exemples de la vie r√©elle.

## Qu'est-ce que le Biais?

Le biais est un terme additionnel dans les mod√®les de machine learning, notamment dans les r√©seaux neuronaux, qui permet au mod√®le d'ajuster les pr√©dictions √† des valeurs plus r√©alistes dans le contexte des donn√©es. C'est un peu comme un ajustement de base qui est ajout√© √† la pr√©diction.

### Exemple de la Vie R√©elle

Imaginons que vous √™tes professeur et que vous devez pr√©dire la note finale d'un √©tudiant bas√©e sur le nombre d'heures d'√©tude. Votre mod√®le initial pourrait simplement multiplier le nombre d'heures par un certain poids pour pr√©dire la note. Cependant, si les notes ont tendance √† inclure un bonus de participation de 10 points que tout le monde re√ßoit, votre mod√®le pr√©dira syst√©matiquement des notes inf√©rieures de 10 points. Le biais, dans ce cas, serait ce bonus de 10 points ajout√© √† la pr√©diction de base pour aligner le mod√®le avec la r√©alit√© observ√©e.

## Pourquoi le Biais est-il Important?

Sans biais, votre mod√®le peut √™tre forc√© √† partir de l'hypoth√®se irr√©aliste que lorsque toutes les entr√©es sont √† z√©ro, la sortie doit aussi √™tre z√©ro. Le biais donne √† votre mod√®le plus de flexibilit√© : il lui permet de commencer √† pr√©dire √† partir d'un point diff√©rent de z√©ro.

### Exemple de R√©glage du Biais

Prenons un exemple simple de chauffage d'une maison. Si vous cr√©ez un mod√®le pour pr√©dire la quantit√© de chaleur n√©cessaire pour chauffer une maison en fonction de la temp√©rature ext√©rieure, les poids ajusteront l'importance de la temp√©rature ext√©rieure, mais le biais pourrait repr√©senter le chauffage minimal n√©cessaire, m√™me lorsque la temp√©rature ext√©rieure est agr√©able. Sans ce biais, votre mod√®le pourrait sous-estimer le besoin de chauffage lors des jours l√©g√®rement frais.

## Les Poids (Weights)

Les poids dans un r√©seau neuronal sont des facteurs qui pond√®rent l'importance des entr√©es re√ßues. Si nous revenons √† l'exemple de l'√©tudiant, le poids pourrait repr√©senter combien chaque heure d'√©tude am√©liore la note de l'√©tudiant. Un poids plus √©lev√© signifie que chaque heure suppl√©mentaire d'√©tude est jug√©e plus influente sur la note finale.

## Conclusion

Le biais est un concept crucial qui aide les mod√®les d'apprentissage automatique √† mieux correspondre √† la r√©alit√© complexe des donn√©es qu'ils cherchent √† mod√©liser. Il ajuste la sortie du mod√®le ind√©pendamment des entr√©es, permettant ainsi des pr√©dictions plus pr√©cises et plus adapt√©es. En ajoutant le biais, nous ne supposons pas que nos pr√©dictions commencent √† partir de z√©ro, mais plut√¥t d'un point qui a du sens dans le contexte des donn√©es r√©elles.


# Annexe 3 - code final

- inclure ceci  : [<script src="https://gist.github.com/hrhouma/65357cde6c166b83ca869fdf3a44ab4e.js"></script>](https://gist.github.com/hrhouma/65357cde6c166b83ca869fdf3a44ab4e)
- {%gist 65357cde6c166b83ca869fdf3a44ab4e%}
- git clone https://gist.github.com/65357cde6c166b83ca869fdf3a44ab4e.git



